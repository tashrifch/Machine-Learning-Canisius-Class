{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f75f88-79f0-458a-a113-66ab894b298a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using TensorBoard to view results when using TensorFlow\n",
    "\n",
    "TensorBoard is a very fussy piece of software.  It was written in a Linux environment, and while it works in windows,  there are a number of issues related to how it\n",
    "starts and stops operations.\n",
    "\n",
    "It is a server that reads \"log\" files from various TensorFlow operations and shows you results in a browser.   It can run in a browser window, or as a plug-in within\n",
    "a Jupyter notebook.  To get it to completely stop operating you have to:\n",
    "    \n",
    "    -Exit Jupyter notebook or Jupyter lab,  and stop the Jupyter server\n",
    "    -Clear the log files and Tensorboard .info files \n",
    "\n",
    "https://www.tensorflow.org/tensorboard/get_started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6706c6-7db6-4373-aeef-ef5b420e7a57",
   "metadata": {},
   "source": [
    "This file is really just a test-file to see if we have TensorBoard running and to sort out issues related to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "085fb7fe-a404-4682-9302-38fc757252fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab98d8e-e90d-4fa3-b23c-c0cc2216486f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Manual deletion of old log files\n",
    "\n",
    "Look in your current director for the directory \"logs\", or \"logs_tb\" and remove it, also check c:\\logs and c:\\logs_tb\n",
    "\n",
    "You don't need to do this the first time you run Tensorboard\n",
    "\n",
    "Delete the files before you start Tensorboard!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e87b45-5bb5-443d-a7af-71b158d0e8e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Warning: Tensorflow leaves \".info\" files behind that can interfere the next time you try to start it.  You need to clean these up\n",
    "\n",
    "The code below deletes the tensorboard .info files,   you will need to replace hdavi with your username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f98d2e9-6cd2-4b49-b03a-0311270261a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard does not shut down cleanly on it's own.  You have to manually delete a file so that it does not restart\n",
    "# using the previous data set.   Shut it down (on Windows) using this command,   you need to change the user name from hdavi to your\n",
    "# user name\n",
    "\n",
    "dir = \"C:\\\\Users\\\\hdavi\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\"\n",
    "for f in os.listdir(dir):\n",
    "    os.remove(os.path.join(dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99dc373c-1f6d-469d-8328-f846a0632bc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\logs_tb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# attempt to automatically delete old log files,  works if TensorBoard is not running anywhere\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mlogs_tb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      5\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mdir\u001b[39m, f))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\logs_tb'"
     ]
    }
   ],
   "source": [
    "# attempt to automatically delete old log files,  works if TensorBoard is not running anywhere\n",
    "\n",
    "dir = \"C:\\\\logs_tb\"\n",
    "for f in os.listdir(dir):\n",
    "    os.remove(os.path.join(dir, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f381c54-4cd2-4b2b-8027-8c4222da4029",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tensorflow model,  using the MNIST data set, as an example\n",
    "\n",
    "This is the MNIST digits data set, which we have seen many times now.   The neural net is a pretty standard style construction, there is some dropout, and the layers have been named,  this helps later in viewing the graph of \n",
    "the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc5174b-165f-4748-abef-f66f9e0f13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28),name=\"Flatten\"),\n",
    "    tf.keras.layers.Dense(512, activation='relu',name=\"Dense\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ddcdb02-bb83-4c6d-80bf-d670d64b94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0107455a-ec5c-4306-bfa5-80bed73e0150",
   "metadata": {},
   "source": [
    "Just checking the version of tensorflow being used here- I was using TensorFlow 2.6 which worked well,   I think I did have to install it form conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c7d218a-d477-44a5-80ab-10c649050bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# checking behavior of Tensorflow\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4590b-3b7b-4cd7-a509-c2696980ed73",
   "metadata": {},
   "source": [
    "This is a check to see what devices are available for use in the calculation,   the CPU and the GPU\n",
    "\n",
    "XLA stands for extended linear algebra,  whether this is available or not depends on the the version of the CUDA driver loaded on your machine.   It will speed operations in some cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2da97fbc-d0af-465c-817b-52c4fa155dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ced4a-aec7-49bd-9bb5-8f5b770250c5",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "TensorFlow has callbacks- these are functions specified in the model.fit, or model.predict member function calls that modify the behavior of the training process\n",
    "\n",
    "Here we are adding a callback that will save the loss and the metrics to a log file on disk once per epoch.   The Tensorboard program can then access this log file to display the loss and other info \n",
    "for each step of the training process.    It is sort of like writing the history to disk\n",
    "\n",
    "One other helpful callback we haven't seen is the early stopping callback, which stops the training at a minimum in the cross validation loss.   This is another way to avoid overfitting, by stopping the training early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a7e37bf-cca8-4f27-8e06-9e9ef5a180b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2214 - accuracy: 0.9344 - val_loss: 0.1140 - val_accuracy: 0.9655\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0983 - accuracy: 0.9701 - val_loss: 0.0856 - val_accuracy: 0.9744\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0710 - accuracy: 0.9777 - val_loss: 0.0723 - val_accuracy: 0.9764\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0554 - accuracy: 0.9828 - val_loss: 0.0605 - val_accuracy: 0.9810\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.0675 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fdacc79670>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and train a basic model, kind of short on training epochs, just to save time\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#These are are the steps used to set up a log file that Tensorplot will plot from once the model is fitted\n",
    "# the directory is an \"offset\" from your current working directory.\n",
    "# The callback is a step used in model fitting that writes to the log file\n",
    "\n",
    "log_dir = \"logs_tb/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "575ef657-e78b-4c5b-adb4-77b2f9ad93e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Just to see what this model structure looks like and the number of parameters involved\n",
    "\n",
    "model. summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef1ac4-4901-4d3a-a8c4-7b77710f8dfc",
   "metadata": {},
   "source": [
    "### Using TensorBoard to look at our results\n",
    "\n",
    "TensorBoard can be run alone in a browser window, or we can load an extension into Jupyter lab/notebook, so that TensorBoard runs inside the Notebook.\n",
    "\n",
    "TensorBoard does have it's own server, just as Jupyter notebooks do.  This is why TensorBoard doesn't always shut down correctly particularly on windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d042c472-c067-488e-81d7-2384ce0f13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tensorboard extension for jupyter notebooks,  by loading Tensorboard into Jupyter notebook and then starting it\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "281643eb-c21c-4b34-9033-0270bf7a04e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-134dffbd9d695685\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-134dffbd9d695685\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs_tb/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a6e4c4-a1a8-445a-aea7-7a1cb6fed57f",
   "metadata": {},
   "source": [
    "Question/Action\n",
    "\n",
    "The tensorboard plots show us the training process,  with the loss and accuracy (or other desired metric),  that is helpful and useful\n",
    "\n",
    "It also shows us a graph that shows how the model and the training process is structured, this is the graph of the computations used.  Have a look at it.  It contains a lot of unfamilar terms,   we will cover these a bit later this \n",
    "semester.  YOu can download it as a .png file which makes it easier to look at,   do this and open it in a photo viewer.\n",
    "\n",
    "In the graph view, if you click on the \"Tag\" option on the left side and select \"keras\", it will show you the Keras network structure.   Double click on this graph (\"sequential\"), it will show you more detail of the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a145d711-a110-4d1a-b6b0-26ef2fd90129",
   "metadata": {},
   "source": [
    "Question/Action\n",
    "\n",
    "Add an early stopping callback to this model, and then increase the number of epochs.   (Google tensorflow callbacks).\n",
    "\n",
    "What parameters are available in the early stopping callback to let you control the stopping point?\n",
    "\n",
    "What other possibly useful callbacks are available?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6471ff2f-48dd-4d85-8bdf-3cb09066891a",
   "metadata": {},
   "source": [
    "### Watermarks\n",
    "\n",
    "We may have already discussed this, but below are the watermarks for this file,  they indicate the version of Python used,  other info and then the versions of all the imported libraries.   Nice things to know about a project\n",
    "\n",
    "Like TensorBoard above, this is an add-on extention to Jupyter notebook, not a Python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c39bb8-0890-428c-99ef-cb70f57e5e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f4fdc-e0ab-4250-aae2-165019244d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752dce3b-7291-4f85-bd82-e1a3b270375f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
